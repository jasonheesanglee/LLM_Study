{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI1R4Lk7V+PXSTGI4SjR4Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasonheesanglee/LLM_Study/blob/main/chatgpt_api_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQf-ykh86Huq",
        "outputId": "c25bfffb-6de0-405f-ce90-5ad418c90afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/2.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/2.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m1.7/2.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qqq --upgrade langchain langchain-openai\n",
        "!pip install -qqq -U openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OpenAI_API\")"
      ],
      "metadata": {
        "id": "PGOcKScl6QCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
        "answer = chatgpt.predict(text='why is python the most popular language? answer in Korean.')\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhWNcUrI6Y3y",
        "outputId": "b19bd422-b7a9-4b79-b67a-6b77fb20c317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파이썬이 가장 인기 있는 언어인 이유는 다양한 이유가 있습니다. 첫째, 파이썬은 배우기 쉽고 이해하기 쉬운 언어이기 때문에 초보자들도 쉽게 시작할 수 있습니다. 둘째, 파이썬은 다양한 분야에서 활용되는 범용 언어로서 데이터 분석, 인공지능, 웹 개발 등 여러 분야에서 사용되기 때문에 널리 인기를 얻고 있습니다. 또한, 파이썬은 오픈소스이기 때문에 무료로 이용할 수 있고 커뮤니티가 활발하여 다양한 라이브러리와 도구를 쉽게 찾을 수 있습니다. 이러한 이유들로 파이썬은 가장 인기 있는 언어 중 하나로 평가받고 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=0)\n",
        "chatgpt.predict(text='why is python the most popular language? answer in Korean.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "MERtFSTD7A4a",
        "outputId": "f8cceff2-4f4a-482f-d9c4-47191f2b2790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'파이썬이 가장 인기 있는 언어인 이유는 다양한 이유가 있습니다. 먼저 파이썬은 배우기 쉽고 읽기 쉬운 문법을 가지고 있어 초보자들도 쉽게 접근할 수 있습니다. 또한 다양한 분야에서 활용이 가능하며 데이터 분석, 인공지능, 웹 개발 등 다양한 분야에서 사용되어 유연성이 뛰어나다는 점도 인기를 끌고 있습니다. 또한 무료이고 오픈 소스이기 때문에 누구나 쉽게 사용할 수 있고 커뮤니티가 활발하여 문제 해결이 쉽다는 점도 파이썬의 인기를 높이는 요인입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=1)\n",
        "chatgpt.predict(text='why is python the most popular language? answer in Korean.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "2DQxti3w8ovy",
        "outputId": "63aee8dc-0079-4914-e848-a05f01944463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'파이썬은 가장 인기 있는 프로그래밍 언어인 이유는 다양한 이유가 있습니다. 먼저, 파이썬은 배우기 쉽고 사용하기 편리한 문법을 가지고 있어 초보자부터 전문가까지 다양한 사람들이 쉽게 접근할 수 있습니다. 또한 다양한 분야에서 활용될 수 있는 다양한 라이브러리와 모듈, 그리고 데이터 분석, 인공지능, 웹 개발 등의 다양한 영역에서 사용될 수 있어서 많은 사람들이 선호하는 언어가 되었습니다. 또한 오픈소스이며 커뮤니티가 활발하여 다양한 지원이 가능하며 개발 생산성도 뛰어나기 때문에 많은 사람들이 파이썬을 사용하는 것입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=1)\n",
        "chatgpt.predict(text='why is python the most popular language? answer in Korean.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "Ltwyitj28ptr",
        "outputId": "bd1c2f3d-65f2-4f88-df4f-a6ca98b51be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파이썬이 가장 인기 있는 언어인 이유는 다양한 분야에서 사용이 가능하고 문법이 간결하며 다양한 라이브러리, 프레임워크 및 도구가 풍부하여 개발 및 데이터 분석 등에 활용하기에 매우 편리하기 때문입니다. 또한 배우기 쉽고 커뮤니티가 활발하여 지식을 공유하고 문제를 해결할 수 있어서 많은 사람들이 파이썬을 선호하는 것으로 보입니다."
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'파이썬이 가장 인기 있는 언어인 이유는 다양한 분야에서 사용이 가능하고 문법이 간결하며 다양한 라이브러리, 프레임워크 및 도구가 풍부하여 개발 및 데이터 분석 등에 활용하기에 매우 편리하기 때문입니다. 또한 배우기 쉽고 커뮤니티가 활발하여 지식을 공유하고 문제를 해결할 수 있어서 많은 사람들이 파이썬을 선호하는 것으로 보입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=0)\n",
        "messages = [\n",
        "    SystemMessage(\n",
        "        content='You are a helpful assistant that translate English to Korean.'\n",
        "    ),\n",
        "    HumanMessage(\n",
        "        content='I love LangChain.'\n",
        "    ),\n",
        "]\n",
        "response_langchain = chatgpt(messages)\n",
        "response_langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swINzRiE9PSa",
        "outputId": "7b5bb281-2a63-4ebb-9a8e-fcc470ff5477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='저는 LangChain을 좋아합니다.')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_langchain.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1L2eEx3E9zm8",
        "outputId": "7f333091-e296-483d-9527-af4725c2e594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'저는 LangChain을 좋아합니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
        "answer = chat(\n",
        "    [SystemMessage(\n",
        "        content='당신은 공부 계획을 세워주는 스터디 플래너 머신입니다. 사용자의 공부 주제를 입력받으면, 이를 학습하기 위한 공부 계획을 작성합니다.'\n",
        "        ),\n",
        "     HumanMessage(\n",
        "         content='저는 Large Language Model을 공부하고 싶어요'\n",
        "     )\n",
        "     ]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHchMV6M-Oi8",
        "outputId": "101cfcff-3860-4114-f484-41b7b12829eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "좋습니다, Large Language Model을 공부하기 위한 계획을 세워볼게요.\n",
            "\n",
            "1. **기본 개념 이해**\n",
            "   - Large Language Model이란 무엇인지, 어떻게 작동하는지 학습합니다.\n",
            "   - GPT-3, BERT, T5 등의 대표적인 Large Language Model에 대한 비교 연구를 찾아 볼 수 있습니다.\n",
            "\n",
            "2. **모델 구조 분석**\n",
            "   - Large Language Model의 아키텍처, 셀프 어텐션 메커니즘, 레이어 정규화 등의 기술적인 요소를 학습합니다.\n",
            "   - 페이퍼 리뷰나 기술 블로그를 통해 심층적으로 분석해 볼 수 있습니다.\n",
            "\n",
            "3. **모델 훈련과 평가**\n",
            "   - Large Language Model을 훈련시키는 방법과 주요 성능 평가 지표에 대해 학습합니다.\n",
            "   - 실제로 GPT-3나 BERT를 훈련시키는 과정에 대해 연구하거나 튜토리얼을 따라해 볼 수 있습니다.\n",
            "\n",
            "4. **응용 분야 탐구**\n",
            "   - Large Language Model이 어떻게 응용되고 있는지, 자연어 처리, 대화 시스템, 요약 등 다양한 분야에서의 활용 사례를 찾아 봅니다.\n",
            "   - 해당 분야에서의 최신 동향과 실제적인 활용 사례를 조사합니다.\n",
            "\n",
            "5. **프로젝트 구상**\n",
            "   - 본 공부를 바탕으로 Large Language Model을 활용한 프로젝트를 계획합니다. 예를 들어, 특정 분야의 자연어 생성, 챗봇 시스템 구축 등의 프로젝트를 고려해 볼 수 있습니다.\n",
            "\n",
            "이러한 단계를 따라가면서 Large Language Model에 대한 전반적인 이해를 높일 수 있을 것입니다. 부족한 부분이나 더 관심 있는 주제가 있다면 추가적으로 계획을 세울 수도 있겠네요!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uB0ewwV-9HZ",
        "outputId": "c6171e58-7272-4117-9ed9-ea28c8911639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "좋습니다, Large Language Model을 공부하기 위한 계획을 세워볼게요.\n",
            "\n",
            "1. **기본 개념 이해**\n",
            "   - Large Language Model이란 무엇인지, 어떻게 작동하는지 학습합니다.\n",
            "   - GPT-3, BERT, T5 등의 대표적인 Large Language Model에 대한 비교 연구를 찾아 볼 수 있습니다.\n",
            "\n",
            "2. **모델 구조 분석**\n",
            "   - Large Language Model의 아키텍처, 셀프 어텐션 메커니즘, 레이어 정규화 등의 기술적인 요소를 학습합니다.\n",
            "   - 페이퍼 리뷰나 기술 블로그를 통해 심층적으로 분석해 볼 수 있습니다.\n",
            "\n",
            "3. **모델 훈련과 평가**\n",
            "   - Large Language Model을 훈련시키는 방법과 주요 성능 평가 지표에 대해 학습합니다.\n",
            "   - 실제로 GPT-3나 BERT를 훈련시키는 과정에 대해 연구하거나 튜토리얼을 따라해 볼 수 있습니다.\n",
            "\n",
            "4. **응용 분야 탐구**\n",
            "   - Large Language Model이 어떻게 응용되고 있는지, 자연어 처리, 대화 시스템, 요약 등 다양한 분야에서의 활용 사례를 찾아 봅니다.\n",
            "   - 해당 분야에서의 최신 동향과 실제적인 활용 사례를 조사합니다.\n",
            "\n",
            "5. **프로젝트 구상**\n",
            "   - 본 공부를 바탕으로 Large Language Model을 활용한 프로젝트를 계획합니다. 예를 들어, 특정 분야의 자연어 생성, 챗봇 시스템 구축 등의 프로젝트를 고려해 볼 수 있습니다.\n",
            "\n",
            "이러한 단계를 따라가면서 Large Language Model에 대한 전반적인 이해를 높일 수 있을 것입니다. 부족한 부분이나 더 관심 있는 주제가 있다면 추가적으로 계획을 세울 수도 있겠네요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "llm_result = llm.generate(['점심에 관한 농담해줘', 'BTS 가사 느낌으로 시를 만들어줘']*3)"
      ],
      "metadata": {
        "id": "GWGiXnwG95HC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}